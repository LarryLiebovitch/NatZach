{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e222089-43a3-4282-8a17-aaf101bdcbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import load_npz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "from countmatrix_editor import filter_countmatrix, make_dicts, quotient_countmatrix, w2c_totable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b31e7d32-0da8-47ff-ba18-2d2445aab347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412154</th>\n",
       "      <td>necroid</td>\n",
       "      <td>412154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675282</th>\n",
       "      <td>vacationshouldremainthesame</td>\n",
       "      <td>675282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700134</th>\n",
       "      <td>whites</td>\n",
       "      <td>700134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541450</th>\n",
       "      <td>ronnit</td>\n",
       "      <td>541450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459385</th>\n",
       "      <td>parodyexempt</td>\n",
       "      <td>459385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364252</th>\n",
       "      <td>majedie</td>\n",
       "      <td>364252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575601</th>\n",
       "      <td>shrinkability</td>\n",
       "      <td>575601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65687</th>\n",
       "      <td>beingimporte</td>\n",
       "      <td>65687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41368</th>\n",
       "      <td>artypoker</td>\n",
       "      <td>41368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594274</th>\n",
       "      <td>spirometric</td>\n",
       "      <td>594274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               word     col\n",
       "412154                      necroid  412154\n",
       "675282  vacationshouldremainthesame  675282\n",
       "700134                       whites  700134\n",
       "541450                       ronnit  541450\n",
       "459385                 parodyexempt  459385\n",
       "364252                      majedie  364252\n",
       "575601                shrinkability  575601\n",
       "65687                  beingimporte   65687\n",
       "41368                     artypoker   41368\n",
       "594274                  spirometric  594274"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import targets (not needed for this test)\n",
    "targets = pd.read_csv('sparse data/count_target.csv')\n",
    "\n",
    "#Import vocab/column dictionary\n",
    "with open('sparse data/vocab_json_file.json','r') as f:\n",
    "    c2w = json.load(f)\n",
    "c2w = {int(k):v for k,v in c2w.items()}\n",
    "w2c = {v:k for k,v in c2w.items()}\n",
    "\n",
    "#import sparse matrix of word counts\n",
    "textcv = load_npz('sparse data/count_matrix.npz')\n",
    "\n",
    "#Create vocab dataframe from dictionary\n",
    "vocab = w2c_totable(w2c)\n",
    "\n",
    "vocab.iloc[np.random.randint(0,vocab.shape[0],size = 10),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abe5ccb-6afe-4f22-9e52-098a68ceeeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_subvocab(subvocab, origmat, subdict, origdict, k = 50):\n",
    "    words = subvocab['word'].values\n",
    "    for k in range(k):\n",
    "        word = np.random.choice(words)\n",
    "        print(f'Occurences of \"{word}\" match in the two matrices: ', (origmat.getcol(origdict[word]) != subset.getcol(subdict[word])).sum()==0)\n",
    "\n",
    "def test_merged(rel, mergedvocab, mergedmat, origmat, mergedict, origdict, k = 50):\n",
    "    words = mergedvocab['word'].values\n",
    "    keys =  rel.keys()\n",
    "    for k in range(k):\n",
    "        word = np.random.choice(words)\n",
    "        while word in keys:\n",
    "            word = np.random.choice(words)\n",
    "        print(f'Occurences of \"{word}\" match in the two matrices: ', (origmat.getcol(origdict[word]) != mergedmat.getcol(mergedict[word])).sum()==0)\n",
    "\n",
    "def test_eqrel(rel, originalmat, mergedmat, originaldict, mergeddict):\n",
    "    for key, values in rel.items():\n",
    "        print(f'Occurences of \"{key}\" in merged matrix match total occurrences of \"{key}\"',\n",
    "              *[f', \"{value}\"' for value in values[:-1]],\n",
    "              *[',' for k in set('*') if len(values)>1],\n",
    "              f'and \"{values[-1]}\" in orginal: ',\n",
    "              (mergedmat.getcol(mergeddict[key]) != (sum([originalmat.getcol(originaldict[value]) for value in values]) + originalmat.getcol(originaldict[key]))).sum() == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b640817-6325-4c0c-977c-813e90dd5a64",
   "metadata": {},
   "source": [
    "# Test dropping words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4780158f-6f04-4ed3-95ae-c93bf8cdec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to subset vocab table: 0.03452587127685547\n",
      "New vocab is smaller by 100 lexical items\n"
     ]
    }
   ],
   "source": [
    "random_drops = np.random.choice(vocab['col'].values, size = 100, replace = False) #choose 100 random words to drop from the vocab\n",
    "start = time.time()\n",
    "smaller_vocab = vocab[~vocab['col'].isin(random_drops)].copy() #create smaller vocab with words dropped (columns from original)\n",
    "end = time.time()\n",
    "print(f'Time to subset vocab table: {end-start}')\n",
    "print(f'New vocab is smaller by {vocab.shape[0] - smaller_vocab.shape[0]} lexical items') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4323069b-dc9c-45d6-a1c8-6195a7848308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to subset matrix and vocab table: 1.310939073562622\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "subvocab, subset = filter_countmatrix(smaller_vocab, textcv) #use smaller vocab to subset the matrix (remove columns), and renumber vocab table\n",
    "end = time.time()\n",
    "print(f'Time to subset matrix and vocab table: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "610348ab-1716-4c53-bed3-d6300e9a3737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create vocab dictionaries from table: 5.505706071853638\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "sub_w2c, sub_c2w = make_dicts(subvocab) #convert new vocab table to dictionaries\n",
    "end = time.time()\n",
    "print(f'Time to create vocab dictionaries from table: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d7a7b32-a465-47e3-b5ad-40f23b792cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurences of \"satnam\" match in the two matrices:  True\n",
      "Occurences of \"systemized\" match in the two matrices:  True\n",
      "Occurences of \"hsdailyfeature\" match in the two matrices:  True\n",
      "Occurences of \"vogle\" match in the two matrices:  True\n",
      "Occurences of \"rustup\" match in the two matrices:  True\n",
      "Occurences of \"falltuesdayekttitab\" match in the two matrices:  True\n",
      "Occurences of \"gpcflatlng\" match in the two matrices:  True\n",
      "Occurences of \"oonly\" match in the two matrices:  True\n",
      "Occurences of \"ovma\" match in the two matrices:  True\n",
      "Occurences of \"broadcastersinclude\" match in the two matrices:  True\n",
      "Occurences of \"veneral\" match in the two matrices:  True\n",
      "Occurences of \"nnotice\" match in the two matrices:  True\n",
      "Occurences of \"designrequirement\" match in the two matrices:  True\n",
      "Occurences of \"casiegraphic\" match in the two matrices:  True\n",
      "Occurences of \"inportant\" match in the two matrices:  True\n",
      "Occurences of \"incurred\" match in the two matrices:  True\n",
      "Occurences of \"worksugarsugarboard\" match in the two matrices:  True\n",
      "Occurences of \"youwin\" match in the two matrices:  True\n",
      "Occurences of \"udyanotsav\" match in the two matrices:  True\n",
      "Occurences of \"rslk\" match in the two matrices:  True\n",
      "Occurences of \"œsurprisingly\" match in the two matrices:  True\n",
      "Occurences of \"aspekt\" match in the two matrices:  True\n",
      "Occurences of \"guangzhoushijingjinyiliaokejiyouxiangongsi\" match in the two matrices:  True\n",
      "Occurences of \"personis\" match in the two matrices:  True\n",
      "Occurences of \"hypefactor\" match in the two matrices:  True\n",
      "Occurences of \"badulipar\" match in the two matrices:  True\n",
      "Occurences of \"alexclosedividendscapital\" match in the two matrices:  True\n",
      "Occurences of \"artgallery\" match in the two matrices:  True\n",
      "Occurences of \"conductibility\" match in the two matrices:  True\n",
      "Occurences of \"šafránkováemail\" match in the two matrices:  True\n",
      "Occurences of \"shushme\" match in the two matrices:  True\n",
      "Occurences of \"coordinaire\" match in the two matrices:  True\n",
      "Occurences of \"ineos\" match in the two matrices:  True\n",
      "Occurences of \"boseto\" match in the two matrices:  True\n",
      "Occurences of \"bartonjo\" match in the two matrices:  True\n",
      "Occurences of \"mbms\" match in the two matrices:  True\n",
      "Occurences of \"flyovering\" match in the two matrices:  True\n",
      "Occurences of \"oralid\" match in the two matrices:  True\n",
      "Occurences of \"nopa\" match in the two matrices:  True\n",
      "Occurences of \"acturum\" match in the two matrices:  True\n",
      "Occurences of \"scopeguide\" match in the two matrices:  True\n",
      "Occurences of \"managehis\" match in the two matrices:  True\n",
      "Occurences of \"sieme\" match in the two matrices:  True\n",
      "Occurences of \"fullhard\" match in the two matrices:  True\n",
      "Occurences of \"thorium\" match in the two matrices:  True\n",
      "Occurences of \"cubicles\" match in the two matrices:  True\n",
      "Occurences of \"publiclyavailable\" match in the two matrices:  True\n",
      "Occurences of \"nonmandated\" match in the two matrices:  True\n",
      "Occurences of \"voxpop\" match in the two matrices:  True\n",
      "Occurences of \"exploitable\" match in the two matrices:  True\n"
     ]
    }
   ],
   "source": [
    "#Test if new dictionary matches for a sample of words\n",
    "test_subvocab(subvocab, textcv, sub_w2c, w2c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21204816-2b86-40ac-890e-606fe4028038",
   "metadata": {},
   "source": [
    "# Testing merging words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988ed8f4-f34d-46b2-b0f2-cba148e367c2",
   "metadata": {},
   "source": [
    "For the sake of example, we will merge extra words together which we may want to keep separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad2c724d-9b29-4e69-8502-c787719363f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqrel = {'america':['american', 'americanize', 'americanisation','americanization'],\n",
    "        'color':['colour']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4122ca88-173a-4338-84ba-7eb8997b4e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create merged matrix and vocab table: 15.622627973556519\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mergedvocab, mergedmatrix = quotient_countmatrix(eqrel,vocab, textcv)\n",
    "end = time.time()\n",
    "print(f'Time to create merged matrix and vocab table: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b885151f-b68d-42a6-a805-f180c05b6ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create vocab dictionaries from table: 5.371376037597656\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "w2c_merge, c2w_merge = make_dicts(mergedvocab)\n",
    "end = time.time()\n",
    "print(f'Time to create vocab dictionaries from table: {end-start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c482ae5-e496-45ab-b0db-0f38ffebb987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurences of \"parvaaz\" match in the two matrices:  True\n",
      "Occurences of \"designrequirement\" match in the two matrices:  True\n",
      "Occurences of \"learnednot\" match in the two matrices:  True\n",
      "Occurences of \"cumberlidge\" match in the two matrices:  True\n",
      "Occurences of \"simonsberg\" match in the two matrices:  True\n",
      "Occurences of \"ptc\" match in the two matrices:  True\n",
      "Occurences of \"hoffmann\" match in the two matrices:  True\n",
      "Occurences of \"ndeam\" match in the two matrices:  True\n",
      "Occurences of \"toneed\" match in the two matrices:  True\n",
      "Occurences of \"pointspartner\" match in the two matrices:  True\n",
      "Occurences of \"dobyli\" match in the two matrices:  True\n",
      "Occurences of \"onrushing\" match in the two matrices:  True\n",
      "Occurences of \"inseam\" match in the two matrices:  True\n",
      "Occurences of \"sinyoungcho\" match in the two matrices:  True\n",
      "Occurences of \"yuntie\" match in the two matrices:  True\n",
      "Occurences of \"oequieten\" match in the two matrices:  True\n",
      "Occurences of \"elemec\" match in the two matrices:  True\n",
      "Occurences of \"fraudulenty\" match in the two matrices:  True\n",
      "Occurences of \"zázemí\" match in the two matrices:  True\n",
      "Occurences of \"electroscope\" match in the two matrices:  True\n",
      "Occurences of \"laskowsky\" match in the two matrices:  True\n",
      "Occurences of \"jalne\" match in the two matrices:  True\n",
      "Occurences of \"oumph\" match in the two matrices:  True\n",
      "Occurences of \"abijit\" match in the two matrices:  True\n",
      "Occurences of \"fosi\" match in the two matrices:  True\n",
      "Occurences of \"elvaston\" match in the two matrices:  True\n",
      "Occurences of \"bahamasair\" match in the two matrices:  True\n",
      "Occurences of \"medigard\" match in the two matrices:  True\n",
      "Occurences of \"fishers\" match in the two matrices:  True\n",
      "Occurences of \"optichrome\" match in the two matrices:  True\n",
      "Occurences of \"nadar\" match in the two matrices:  True\n",
      "Occurences of \"mainnew\" match in the two matrices:  True\n",
      "Occurences of \"bluefoot\" match in the two matrices:  True\n",
      "Occurences of \"intitative\" match in the two matrices:  True\n",
      "Occurences of \"fannne\" match in the two matrices:  True\n",
      "Occurences of \"poat\" match in the two matrices:  True\n",
      "Occurences of \"umpteem\" match in the two matrices:  True\n",
      "Occurences of \"presskitpininfarinabattista\" match in the two matrices:  True\n",
      "Occurences of \"depalla\" match in the two matrices:  True\n",
      "Occurences of \"parasrampuria\" match in the two matrices:  True\n",
      "Occurences of \"ternent\" match in the two matrices:  True\n",
      "Occurences of \"neighbors\" match in the two matrices:  True\n",
      "Occurences of \"bounddonvale\" match in the two matrices:  True\n",
      "Occurences of \"whrb\" match in the two matrices:  True\n",
      "Occurences of \"wnrmnft\" match in the two matrices:  True\n",
      "Occurences of \"wassertrdingen\" match in the two matrices:  True\n",
      "Occurences of \"bildmaterial\" match in the two matrices:  True\n",
      "Occurences of \"blooddonation\" match in the two matrices:  True\n",
      "Occurences of \"disulfonic\" match in the two matrices:  True\n",
      "Occurences of \"maengwyn\" match in the two matrices:  True\n"
     ]
    }
   ],
   "source": [
    "#test if corresponding columns match for vocab items not merged with others\n",
    "test_merged(eqrel, mergedvocab, mergedmatrix,textcv,w2c_merge, w2c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c7bd2f6-0018-492a-95a9-9310f08c3a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurences of \"america\" in merged matrix match total occurrences of \"america\" , \"american\" , \"americanize\" , \"americanisation\" , and \"americanization\" in orginal:  True\n",
      "Occurences of \"color\" in merged matrix match total occurrences of \"color\" and \"colour\" in orginal:  True\n"
     ]
    }
   ],
   "source": [
    "#test that equivalence classes summed correctly\n",
    "test_eqrel(eqrel,textcv,mergedmatrix,w2c,w2c_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e28245-79ac-45c0-84b2-99cca9403ed9",
   "metadata": {},
   "source": [
    "Worth making dictionary as dictionary access works an order of magnitude faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98a36993-775c-4b73-8560-0543c714706e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nufem'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = np.random.choice(vocab['word'].values)\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff8a50a6-7310-40e0-9323-add06c5d83c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.2 ms ± 2.12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "vocab[vocab.word == word].loc[:,'col'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc92159f-7dae-460a-bc7b-03aee3ea030f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 57.27 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "264 ns ± 573 ns per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 10 -r 7\n",
    "w2c[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "072a00c2-d497-402d-8f0f-50cfc5623ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 ns ± 0.0324 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "w2c[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15145d52-b21d-4428-91c9-00d34ee415e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
