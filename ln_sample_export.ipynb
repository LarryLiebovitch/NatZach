{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbe6fae-fd6c-4ad7-a75d-0e2720cd4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy.sparse import save_npz, load_npz\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fbd5c68-a775-4fc8-b39f-af0805a77efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataframe size: 818.676156\n",
      "Number of empty_articles from sample: 36\n",
      "Average reported word length of empty articles: 6.58\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('lemmatized_ln.csv', index_col = 0)\n",
    "print(f\"Total dataframe size: {sys.getsizeof(data)/1e6:.2f} mb\")\n",
    "\n",
    "empty_articles = data[data.content_lem.isnull()]\n",
    "print(f\"Number of empty_articles from sample: {empty_articles.shape[0]}\")\n",
    "print(f\"Average reported word length of empty articles: {empty_articles.wordCount.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bd697f-2ef5-429c-9be1-24bd4c7e1288",
   "metadata": {},
   "source": [
    "Count vectorize and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db3ff5a4-b733-4572-88af-9feb195f4933",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[data.content_lem.notnull()] #strip out empty articles\n",
    "\n",
    "countv = CountVectorizer()\n",
    "cv_text = countv.fit_transform(x.content_lem) \n",
    "save_npz('cv_text_ln_sample.npz', cv_text) #export as npz\n",
    "\n",
    "vocab_swap = {v: k for k, v in countv.vocabulary_.items()} #vocab dictionary\n",
    "with open('vocab_ln_sample.txt', 'w') as f:\n",
    "    f.write(json.dumps(vocab_swap)) #save as json\n",
    "\n",
    "#Sample encodings\n",
    "print(list(countv.vocabulary_.keys())[:10])\n",
    "print(list(countv.vocabulary_.values())[:10])\n",
    "\n",
    "print(f'Observations: {cv_text.shape[0]}')\n",
    "print(f'Vocab size: {cv_text.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c8372b0-1e26-45f7-a843-b06f3d4844f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[['target','country']].to_csv('country_labels_ln_sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daf92c1-1770-4a19-8307-6cb2c1deeaba",
   "metadata": {},
   "source": [
    "Test loads:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902b91f4-2b31-4759-8aca-e902b4b29321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix file size: 341.03 mb\n"
     ]
    }
   ],
   "source": [
    "cv_text = load_npz('cv_text_ln_sample.npz') #load sparse\n",
    "with open('vocab_ln_sample.txt', 'r') as f:\n",
    "    vocab = json.loads(f.read()) #load vocab dict\n",
    "labels = pd.read_csv('country_labels_ln_sample.csv', index_col = 0) #load labels\n",
    "    \n",
    "print(f\"Sparse matrix file size: {cv_text.data.nbytes /1e6:.2f} mb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
